{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOKENIZERS\n",
    "\n",
    "- Mục đích: dịch văn bản thành dữ liệu có thể được xử lý bới mô hình. Mô hình có thể xử lý dạng số -> token cần chuyern đổi đầu vào văn bản của chúng ta thành dữ liệu số.\n",
    "\n",
    "Dữ liệu thường được xử lý là văn bản thô: Ví dụ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jim Henson was a puppeteer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "             Cần chuyển thành số -> Mục tiêu là tìm ra cách biểu diễn có ý nghĩa nhất đối với mô hình(cách biểu diễn nhỏ nhất)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CÁC THUẬT TOÁN TOKENIZER:\n",
    "\n",
    "### Dựa trên từ\n",
    "\n",
    "Trong hình ảnh bên dưới, mục tiêu tách văn bản thô thành các từ và tìm biểu diễn số cho mỗi từ:\n",
    "\n",
    "![](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/word_based_tokenization-dark.svg)\n",
    "\n",
    "sử dụng khoảng trắng để tokenize tách văn bản thành các từ sử dụng split():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'Khanh']\n"
     ]
    }
   ],
   "source": [
    "text = \"My name is Khanh\"\n",
    "print(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngoài ra có các biến thể của tokenizer mức từ với các quy tắc bsung cho dấu câu. Với loại tokenizer này, ta có thể đúc kết với một bộ từ khá lớn, trong đó từ vựng đc xdinh bằng tổng số token độc lập mà chúng ta có trong kho của mình.\n",
    "\n",
    "Mỗi từ đc gán 1 ID, 0 - n.\n",
    "\n",
    "Token ko xác định, [UNK] hoặc <unk>. Sử dụng tokenizer mức ký tự để giảm thiểu token ko xác định "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dự trên ký tự\n",
    "\n",
    "- CÓ vốn từ ít hơn nhiều\n",
    "- Có ít token ngoài bộ từ vựng\n",
    "\n",
    "Vấn đề dấu cách và các dấu câu:\n",
    "\n",
    "![](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/character_based_tokenization-dark.svg)\n",
    "\n",
    "Biểu diễn dựa trên các ký tự chứ ko phải từ. \n",
    "\n",
    "Chú ý: trong khi một từ chỉ là một token duy nhất khi token dựa trên từ, nó có thể chuyển thành 6 token khi chuyển thành các ký tự.\n",
    "\n",
    "-> Sử dụn kỹ thuật thuwes ba để kết hợp: Tokenize theo từ phụ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token theo từ phụ\n",
    "\n",
    "Nguyên tắc: các từ thường xuyên ko đc chia thành các từ phù hợp nhỏ hơn, nhưng các từ hiếm phải đc phân tách thành các từ phụ có ý nghĩa.\n",
    "\n",
    "VD: \"annoyingly\"(khó chịu) là 1 từ hiếm, có thể chuyển thành \"annoying\" và \"ly\". Cả hai đều có khả năng xuất hiện thường xuyên hơn dưới dạn từ phụ độc lập.\n",
    "\n",
    "ví dụ thuật toán theo từ phụ:\n",
    "\n",
    "![](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/bpe_subword-dark.svg)\n",
    "\n",
    "Nhiều ý nghĩa về mặt ngữ nghĩa. Vd \"tokenization\" đc tách, cả hai đều có nghĩa và đồng thời tiết kiệm không gian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các kỹ thuật khác\n",
    "\n",
    "- Byte-level BPE (BPE cấp byte) đc sd trong GPT-2\n",
    "- WordPiece đc sử dụng trong BERT\n",
    "- SentencePiece hoặc Unigram đc sd trong một số mô hình đa ngôn ngữ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD và SAVE\n",
    "\n",
    "Giống với kiến trúc của mô hình.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lớp AUtoTokenizer sẽ lấy lớp tokenizer thích hợp trong thư viện dựa trên tên checkpoint và có thể sử dụng trực tiếp với bất kỳ checkpoint nào"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Ex:\n",
    "tokenizer(\"Using a Transformer network is simple\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    {'input_ids': [101, 7993, 170, 11303, 1200, 2443, 1110, 3014, 102],\n",
    "     'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "     'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"directory_on_my_computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "B1: Chia văn bản thành các từ\n",
    "\n",
    "B2: Chuyển đổi các từ(token) thành các số để xây dựng một tensor từ nó và đưa vào mô hình\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1: Tokenizer\n",
    "\n",
    "Sử dụng phương thức tokenize():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sequence = \"Using a Transformer network is simple\"\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ['Using', 'a', 'transform', '##er', 'network', 'is', 'simple'] \n",
    "\n",
    "\n",
    "Token dựa theo từ phụ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2: ID to input\n",
    "\n",
    "Phương thức convert_tokens_to_ids() của tokenizer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(ids)\n",
    "\n",
    "\n",
    "[7993, 170, 11303, 1200, 2443, 1110, 3014]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHuyển sang tensor thích hợp, làm đầu vào cho một mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode\n",
    "\n",
    "Từ các số thành các từ. Sử dụng decode():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n",
    "print(decoded_string)\n",
    "\n",
    "'Using a Transformer network is simple'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
